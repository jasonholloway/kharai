the same machine can do diffing of csvs

but there is conceptual separation between the two tasks, the two stages

by putting them to execute in turn we lose comparmentalisation: ie errors can kill one stage while leaving the other to carry on happily

though there is an essential coupling between the two stages: diffing shouldonly occur when there is something to newly diff

but failures in diffing shouldn't stop the scraping

so - there are two machines with two states, and the two should be coupled by some kind of stated condition
the /due condition/ isn't just of time, but of state

---

the differ should state that it is only due when the downloader gets ahead of its own cursor
this condition will then span two states, and potentially two rows in the table
as each row has its own version, key and data.

phase needn't be special, though why not

---

the condition could most simply be expressed as an evaluable predicate in javascript
though we want the expression to be actionable close to the data - like a ConditionExpression (though one that spans multiple items)
which can't be
if the state to be compared spans rows then we have to read the entire thing

though our throughput is always going to be small here: data is going to be slim, and how often will our conditions be checked? actually, fairly regularly, after every phase

in evaluating, we want to lazily load states, to minimize what we summon from the cloud
instead of a proper evaluated language, we can 'shallowly embed' using the evaluative glue of the language itself

---

the condition doesn't have to be expressed in data, in fact it's certainly better that it is not

it's part of the runnable spec!

when states change, then each condition gets run to see if it should kick in

and finally, all states should be transactionally written as one

---

what if multiple agents were running at once? then they wouldn't overwrite each other, but they might gazump each other - the spec should be such to allow 
things to coexist as much as possible

what i'm imagining is a workflow of limited size

though if another workflow wanted to read the state of another, it surely could do; streams could be created, not mediated by a crappy condition engine, but by wasteful polling

the benefits of separation, at the cost of efficient timely execution

---

so, we need
- multiple states
	machines should be executed in some arbitrary sequence, so they're concurrent until one waits on another
- a better parsing of 'due'
	two modes, strategies of waiting: no, two /layers/ of waiting
	firstly each machine is only loaded and run if its /due/ value is ready - this saves us loading machines needlessly
	secondly, conditions should be checked if in place
	  and how do we know if a condition is in place? because we know the phase of the machine; and from the phase, we can figure the waiting behaviour
		but conditions can't be per-phase, as phases are multiples - almost nascent machines ready to unfold into full workflows
		while elegant this destroys the simplicity of single-threaded execution and state
		
		conditions are per-machine, but the form of the condition is determined by the /current state/ of the machine, so is singular
		if a machine is due in time, then we load its phase, and...

    maybe the condition check could itself be performed 'manually' within the code of a phase
		the machine will be run, and its waiting phase will just be a loading of another machine's state,
		a checking of it, and a changing of its own phase based on this
		I like this a lot, a big avoidance of building, a commendation of the generality of the underlying model

	--------

so, we need...
- multiple machines
- states loadable via the context
- all states transactionally committed when at rest 
	

the orchestrator of machines is itself a machine, of course
so even the dispatch of machines can be suspended from the original issue

the original machine must be able to load a list of machine names to dispatch
which is its own state

------

but now the thought comes that more state could be given to the original orchestrator itself
machine's phases and due times, for instance, could belong to the orchestrator
then the full state of a machine could be lazily loaded after that point

but now, by vertically separating the state into two classes, into a more private head and more public body, with the possibility of freeing restrictions on the body data
the protection of the body goes too - what if the body is put but not the state? then we'll get inconsistencies

bodies are owned, and writable only by the owning machine

what's to stop another orchestrator, also with the machine listed, from dispatching against its body?
at the same time it is ok for there to be multiple orchestrators, as long as they don't garble the subject machine by their contentious orchestrations

ie phase and version belong to the machine
then the machine can stand as itself

-----

so if the orchestrator is but one machine amongst others
it has its own phase and version (as if these were all owned by /it/, who would own its own phase and version?)

so...
the main requirement is for multiple machine states to be loadable and savable
loading should be via a lazy, cached provider
and then saving of machine states should be done as one big transaction at the end

---

but the orchestrator machine state is itself to be saved
so the loading and saving of states is above the level of the orchestrator
its at the level of the /RUN/

each /RUN/ establishes its provisions (its UoW effectively), loads up its known orchestrator machine
and executes it

but - something is orchestrating the /RUNs/! and this orchestrator has inalienable rights of determining dispatches below
(or, rather, its always possible for it to make sense to have that power)
that is, the above orchestrator should be able to pipe in from above what machines are to be run

in which case, what do we gain by treating the orchestrator as a machine as well?

---

it seems the simpler way of doing itis just having a hard-coded list of machines to execute
these can, for more flexibility, be provided as part of the initial invocation of the run

/there always has to be something invoking the run/

so we will /ALWAYS/ need this mechanism

the question is how much is proper to this layer
child runnables are not needed now, termination isn't needed now
but if it were then we'd need a machine storing the states of things, of owned things
though machineyness is only needed when state has to be protected
whatever... we will always need invocation of a list of machines

---

*we need a RUN*

---

we want to run machines concurrently: there's no point in putting them in series

but then, if one machine changes state before the other manages to get its condition raised?
but this will always occur, given that even if phases are run in series, their order will be arbitrary
and no guarantees can be given; so that's all fine then... yup

---

machines should be dispatched concurrently, at their own pace
but at each interstice there's the possiblity ofupdating the condition table


------------------------------------------

phases should have timings associated so we know whether we should fire them or not
if we're really out of time, we shouldn't proceed to do something very long-running

but the easiest way of doing this would just be to have a time threshold, with no concern about average durations

so, hamfistedly, the threshold can be applied to the start time rather than the putative end time

basically, we don't want to execute anything at all (except for final saving) once the threshold is passed

----------------------------------------

machines will move at their own pace - imagine a machine that gets stuck, not erroring, not terminating
in the meantime its siblings will be forging ahead
so the behaviour of a constellation of machines is not determinate

it would only be so if we forced all machines to operate in lockstep, with a preordained order; here our efficiency evaporates

but some bits can be safely concurrent; others should ultimately be in exactly this lockstep: like we need barriers as well as conditions
eventually...

do conditions even make sense if the listening machine might or might not be around to hear that the condition has changed?
maybe in this case the scheduling should be quite different, in that a listener should be coopted onto the thread of the source

a listener to s3 uploads, for instance, would detect a change, and immediately after the upload would be invoked, blocking the progress of the uploader

to let things move at their own pace, to allow slack, we need buffers
but passing of important data like this is poorly suited to our model: what's better is using monotonic cursors, that can then refer to buffers (s3 is the buffer in this case)

so lockstep isn't needed
how about conditions? they make sense, belonging to the listener, and checked at its pace


-------------------------------------------


instead of saying that the next phase is due a certain time, actions should be able to say 'when something has changed'
though the problem with this is that the comparand is a bit of state that is not serialized, but held in memory

a watch is set, and then checked after every phase of the watched
maybe this condition could in fact be serialized

but then when it comes to initializing the run, we'd presumably check the condition immediately

and if the condition relates to a state we own, we can check it very efficiently ourselves

but if it relates to another state, then we'll have to poll at a certain frequency
this second polling could even be done by the machine itself

---------------------------------------------

how about combos of types and names

given one machine, does it make sense to have multiple other ones of exactly the same type hanging of it
yes - as they may differ significantly in data
data as well as type determines behaviour

------------------------------------------

the role of the time-based scheduler? just to stop scheduling, and to tell us when nothing more has been scheduled

but now we will have an event-based scheduler
that should be dispatched immediately
and will continue as a machine

------------------------------------------

                        //or wait for an incoming event to retrigger us
                        //so the threader still ensures the thread goes forward as one
                        //yet doesnt rely on the scheduler alone

                        //but hooks would have to be put in here?
                        //yes - the condition would be taken from the result
                        //and passed to the state engine
                        //which might immediately trigger our callback

                        //hooks should presumably be loaded before anything else
                        //but there's always the possibility of hooking machines being
                        //dependent on each other, and so a simple ordering like so wouldn't
                        //resolve all situations anyway
                        //either solve it, or live with the poossibility of it occuring

                        //what's the worst that would happen?
                        //a particular machine state could be missed 
                        //and so the supposed guarantee of locality - that nothing would be missed
                        //would be lost in a single unfortunate case

                        //how nice it would be to be certain of seeing every local change

                        //but machines always move at their own pace - you can never be sure that
                        //in the time it has taken to reset the condition
                        //lots of movement in the target hasn't occured and been missed
                        //without a comunicative buffer mechanism (ie an inbox) there's no way round this
                        //sampling approach

                        //so machines always move at their own pace, and are always liable to miss micro movements

                        //that's one mode anyway: another is buffering, another is cooperative yielding and serialization
                        //how would we support these? buffering itself would have its own persistent and evanescent modes
                        //such buffering could be supported using our normal machine mechanism: a persistent buffer would
                        //be commonly available (with local cacheing layer), and producer and consumer would communicate
                        //via exposed state

                        //lockstep transmission could also be done, but only by cooperation of producer and consumer: they could mutually
                        //wait on one another, as interlinked state machines

                        //and how about the other way round? how could we implement the other modes in terms of this one?
                        //lockstep can't pretend to be concurrent, unless it were its own scheduler, executing small participles
                        //with buffering, messages could be sent from here to there, properly like actors
                        //this is sufficient to model anything, but is more complicated in its implementation requirements
                        //there's no need for persistence with our machines

----------------------------------------------------------------------------------------------------

the runner will, if we have a certain delay to wait, create a timer instance that the threader will use to restart itself
similarly, if we require a hook, it will create a hook and feed that to the threader instead

closing the repo will remove hooks
closing the timer will remove timers
then the threader itself can be closed

but the repo should only be closed when all the thread phases have stopped
and we want thread phases to be able to complete if already in flight, as they might have done precious work
so we can't violently stop them from setting their states

maybe the thing to do then is to close the threader first of all, which will stop resumptions
and with this, will stop timers and hooks having any effect

when the threader has stopped all threads at insterstitial points, then a further save should be queued, and we should wait on the saver completing
after the threader has completed, then we can complete the timer and repository
and finally we wait on the saver to complete

so - complete the threader first!

---------------------------------------------------------------------

an efficient stream between two machines would be an hoc coupling of their states

without persistent storage linking the two, one would pass data directly to the other - though the watch mechanism could be forced to do this
the source machine would load a buffer, and then would course through it, updating its own pointer, and its own local buffer, which would be observable
by the sink. It doesn't make sense for all sharable data to be serialized however: a buffer can be refilled, determined by the value of a persistent cursor

what would be the point here however? decoupling of machines, interestingness

but there is a problem in the lossiness of observation: unless the source really were to store a buffer, then observers aren't guaranteed to see all possible data

----------------------------------------------------------

so, diffing our csvs, then...

we want to extract all differences from the csv, and list them in a central log

then aggregators can work their way through them
collecting, projecting whatever they like

also, triggering what they like

--------------------

so, given two files, we need to chug our way through them in batches

ie there's lots of diffing that can be done, but we don't have to do it all at once
in fact, we're limited by how many items we can save at once
25 items at a time...
which is 24 plus a cursor
or well, the cursor belongs to the machine which is a separate saving step

the rows will be saved separately as immutable, idempotently-put resources

our diffing needs to result in a deterministic outputs therefore

both sets need to be firstly ordered, then we can work through them till we have accumulated enough differences to save - then we save the differences
and update the cursor(s) in the machine

then begin again, hopefully finding the buffers still in memory

-------------------------

so: load our buffers, 
sort them 
work through them with dual cursors, accumulating changes
when we have 25 events
save them
save the machine

---------------------------

it'd be nice to be able to stash resources too:
we don't need to persist everything

--------------------------

each member could have their own machine
actively updating their details
only when a new member has their photo filled out will they be announcable

so, 2000 machines, each a row in Dynamo: sounds fine to me

but how to run them? a scheduler needs to intervene
and that scheduler needs a list of sub-machines
which it can run as it likes

the node would know which machines were to run next
say that each user were updated each day
with 2000, that's still 100 an hour: a large amount

and few of these repollings would be worthwhile at all
polling should be as sparse as possible

each polling machine would be given a small number of jobs by a JobAccumulator machine, whose state could be peeked at by the Poller
but polling isn't needed yet...

---------------------------------

for now, all is deterministic
when a member is noticed, then that member has a state, which should switch to one indicating a photo has been stored for them 
what drives this state? while a centralised log would be simplest, with a single machine parping through it

this single machine's state must fatten out to be unmanageable

unless each member were not to be a machine, but were to be a state
the single machine would dispatch these members' behaviours

problematically, however, an index would have to be maintained of not insignificant size
this is true if the states were to be active after all, and not just sinks of data, plugholes

running machines and checking if conditions are momentarily true is itself a kind of polling
assigning of watches: that is, their embedding in a local data structure that can be immediately parsed
is however not - at least if it is the same, it is a vanishing similarity 

the dispatcher as a whole could be thought of as a machine, whose state could be persisted and loaded efficiently, so that individual machines needn't be
speculatively loaded (that is, /polled/)
its network of continuations would therefore be in place, ready for immediate, deterministic resumption

------

a single machine would work through log step by step:
an event would be waited for and read, then the machine would dispatch whatever behaviour
but to do this, each members state would have to be consulted to see how the central event interacted

the cursor on the log is watched, as it is itself a machine, depositing these immutable records into memory (and such immutable records are cacheable)

-------

so, each member's state is a maintainable thing, a thing to be worked individually
similarly the set of members must have behaviours proper to it: eg a notification when we have 100 members
but even beyond this there is a wider domain of states, with proper behaviours here too
one level shouldn't have access to all the states of all others however

it's up to individuals to emit condensable events

but its up to the centralised monolithic log to spawn child machines better scaled to fidelous maintenance of all states

an individual's responsiblity to emit events, is it set by itself? doubtful. the wider world says what it expects
injects the individual with its expectations

how can all this be efficiently dispatched?

--------

each member would belong to a group, a small selection of members
these groups would track the next due time for each member, order them, and then, through their progress,
dispatch these individual member machines one by one

one of these orchestrator nodes would go through its own phases 

i'm imagining buckets of machine references, with times of next dispatch
(or conditionsof next dispatch???)

then the dispatching machine will, repeatedly, see if it has anything to do
and dispatchers will themselves have dispatchers...

a dispatcher, by reading its table, knows what machines to load in order to run them
but how can it load them if it does not own their state?

a dispatcher must own its children, not as immutable records, but as substates, that it itself can load, run subprograms on,
and optimistically persist

there is inevitably this question of ownership, and the answer is pretty clear: some machines must own other machines
though it's also possible that other machines might own the same sub-machines, and this is where optimistic locking decides

the simplest case is that a machine owns itself, and at the highest level of dispatch, this must be the case

a machine can load other machines, then, in the mutable mode, much as it can load blob resources
but how can a machine load itself, but by magic?
ie there has to be a bootstrapper

maybe a machine can, by magic, find itself executing, with some parsable arguments available to it
and its first act is to load itself and run the common dispatch program on its state

then subsidiary dispatchers can be fired by this first one

-----------------

each member would then be its own machine, with its own log of events, and in its journey would publish back to a central log
from which holistic projections could be made

now and again the child machines would be run to poll as they liked
though polling a single site for different pages should be a centralised activity
almost like there should be one meetup polling machine,
but with an organised buffer of intended targets

such a machine could store its targets in multiple rows, as in a circular buffer,

but in this setup there'd be so much churn at the top of the tree
each intermediate node would always be due to execute another
and so would always be active, always saving and loading its updated state.

and above this, the register of intermediate nodes would be even more volatile
and each update of the top would have to be persisted too

or - executions could be made idempotent by marking each visited node with an increasing cursor value
then, if the same execution came in again, the execution could be skipped, protecting state below

but such state would have to be persisted by each party as it was assigned to it, in that moment

a call came in from above, as either a timer had fired or monitored condition been met, and the known cursor is repeatedly updated
on this model each dispatch has its number, which can be stored to protect against costly operations being replayed

the incoming cursor and the outgoing cursor would always be recorded
and an incoming cursor below our persisted input value will always be ignored; or rather, will always result in a successful but empty dispatch

this though relies on deterministic execution of not just one machine, but many
or rather, a well-ordered execution
not all executions have to be so tightly protected, allowing in select cases parallelism

-----------------

the topmost machine will know the number of invocation as it comes in, will increment it itself as an otherwise unprotected machine
and then child machines as they're loaded and dispatched will receive this cursor value as part of their dispatch: these machines,
more protected by an intermediary layer, will only reexecute if this cursor has not been seen before
but as machines are not dispatched in sequence (or rather, as the sausages of their executions are not set end-to-end)
nah - they still can be protected from repeated execution

if they persist themselves, they will store the last successful invocation, whose effects they don't want to repeat

but if one of these machines itself wishes to dispatch further machines, returning the condition of its most pertinent child
these children ought similarly to be protected by persisted markers

why do they even need this protection? double execution is not the worst if all is idempotent. But in external effects, nothing
is idempotent

in this centralised approach, all dispatches below the very top level have numbers
and are hereby protected against double execution

this allows us to persist locally, and not totally, until the last possible moment
a single machine can persist itself, while the nodes above it keep on firing
as long as the route to execution is deterministic

but imagine we are complicated by user input, or the particular response of a volatile web page
user input could determine the delay before the next phase of a machine
and so the order of execution will not be determinate

in which case the cursor approach becomes unworkable

---------------------

and so maybe we can't protect like this
and have to accept the possibility of repeating work
which we can cope with; although it always seems a shame to give up ground
every retreat backs us further into the corner

---------

So the forcible self-persistence of a leaf node: does it also necessitate the persistence of the parent? 
I think it does. The condition of the child changes, and the intermediate index /must/ represent this.

time of next invocation is orderable; but conditional watches? surely not
indexes would have to maintain a list of watches that were placed and communicated upwards (as the parent parent would also need such a list, but this time an aggregaed one)

times can be represented as ranges, arbitrary watches are arbitrary and can only be placed together in their maintained multiplicity

the watch in this case would have to be appended to the target machine, so itself could detect its own changes, and enliven the listener on change
this then becomes message passing

insteadof this, the single dispatcher can be kept, but the data of whole stored in buckets, each one of which stores so many 'rows' of a single type
these rows are then selectively dispatched by the bucket as a small sphere of execution

as long as we have conditions, these conditions must be loaded, and so the machine setting themmust be loaded

in fact we want the opposite of this - to be able to load only a small subset each time, according to pertinence

----------

like sea-anemones, machines should attach themselves to an encompassing index of resumables, according to the kind of resumption they require
they flit from one contact to the other, always connected to root via their resumption
when in flight they need no grounding

a resumer by time is simple enough: each individual machine stores not its full state, but merely its name and due time
then the resumer, itself a state machine, waits till its next hhokis due, then dispatches via some means its waiting registrant

but now we must think of waiting by condition
most fruitfully, let's think of our case with the per-member aggregators, each a machine accumulating its particular state, and each waiting for a particular member's event to appear in their
global log.

there have to be listeners to the global log: they have to themselves be aggregating some state by which we can discern which other machines to activate

image a single index, with each machine encountered registered to it
when each new event pertaining to a machine is encountered, that machine is resumed
and when that machine successfully completes, it overwrites its registration with the index

but how then would a machine flit between indexes, if it has to overwrite the same registration in order to make its progress?
it would transactionally save across two indices, that's how

as always, all execution happens in one space
the only ay to parallelise is to have dependent machines polling their superiors
(imagine the central log dispatched as one process, and per-member aggregators, with their group resumers, another: a central log is a good cut point)

-----------------

but if this is a vision of the future, we now need to confront the present
we have a small complex of machines that download and diff member lists

this information needs to be centrally logged; never mind about what can be built from this log

each log line will be an immutable, very cacheable record
we need a /logger:/ this is exactly the word for what we want
the logger can have its own cache for reads across computations
but, the logger must also be idempotent
that is, the /loggee/ must log with an address

this address could be a locally persisted cursor: for each event found, we know exactly our address as we tot it up by one on each action
but if the code for the differ were to change, and collect events in a different order than before,
it may deduce different addresses for those events

all would be great if everything could be persisted all at once, of course
though, internally, such transactional saving must be much slower; there must ultimately be a locking mechanism

----------------------

the differ has to be the one that maintains its cursor
but then this means it must repeatably and reliably order its output events

if the order of diff deduction differs, then we risk repeat events being logged, or even worse ignored

how else could it be done? the differ would save its last diff in its own state, that can be watched by another
though what would this really get us? a second layer of processing that the differ could do itself

the source data has a unique, monotonic id; each difference needs the same
we can determine an order for diffs: and its needed

-----------------------

an order for diffing: memberId, then event type (event type will always be PUT/DELETE???)
and we need to record the last time of update

nah, there will be other event types
VISITED, ATTENDED
and for these we need to note the time of previous update

-----------------------

so, given two docs, we need to get some well ordered events out: so far, we have ADDED/REMOVED: now we need VISITED/ATTENDED 

then, once we have these, we can add them to a log

but... we don't need these additional events at all, not now

we have all the event types we currently need: what we lack is a log

and the differ will do the logging itself, via transactionl save

-----------------------

so, we just need a way to /save/ arbitrary rows
and everything else will follow

but how will we batch saves?
multiple ones will be created: possibly very many, given a beginning csv of a thousand rows

the saver should save as many as it can, then go again, and again...
ie batches must be small enough to save

savables need to be totted up, and when we reach the limit, we must communicate back to the driving machine
that we can save no more

----------------------

each loaded machine, even if not changed, must be savable
each further row to save must be batched, and only processed at the end of a phase

the differ will keep an index of how far it's got through a particular csv diff

but, once we've saved our buffered states, then the counter is reset

...

do we need to include as-yet unchanged machines when we try to save? yes - because we can't be sure they won't change and need to be saved

an underlying buffer of savables will exist below the machine repo

though - the buffer needs to know from the repo how many places are reserved for machines

almost like, in creating the machine, a handle should be obtained reserving a potential space

-------------------

how would a machine register itself with an index? it would have to wait to cooperate with it 
it would wait for the machine to be in a receptive state
and then its state/message would be flowed to the target in lockstep

but the current method of stating your resumption condition as a returned value
would then be more an offering of a time or condition to another machine to schedule for us;
just as currently the time/condition is offered to the runner directly

maybe due and watch should never be on the actual machine, but always registered with another
if so, we need our method of lockstep registration

the index node will itself have some timer on it
but before the timer fires, it is also open to interruption
and it will be able to handle an incoming communication

----------------------------

updating a machine involves speculatively, optimistically taking a view of its state, trying to
process it, and then finally yielding your overall result back to the machine to either dispatch
fully or ignore if gazumped

the phase behaviours are however till now mutating

it'd be nice if we queued up things to save, and then only if we hadn't been gazumped would the machine
dispatch all we'd returned to it in the form of simple functions

but this goes against our nice idea of receiving feedback on every attempted save
then the behaviour would be in charge of handling failures, and would have chance to persist
whatever state to remember what it had successfully processed and persisted

the phase should return a monadic list of things to save to the machine
which the machine would then attempt to save only on successful update

but then the results of this automated dispatch would be yielded back to the phase
so that the phase itself could persist whatever state

*but* by this time transactional persistence covering the intra-phase state and phase state itself
would be impossible, as the former would have already been dispatched

no - this second callback would not be done after persistence itself, but immediately
before it

the choice here is between getting the machine dispatch mechanism to do the saving of our buffer
versus mutably sticking things in the store then returning to the dispatch mechanism to finish things off

but we can't expect our two communications to the store to be covered by the same transaction locally, unless we were
persisting to per-phase buffer

but how can we expect all persistences to be transactional? there's a distinciton between machine state
and 'external' data rows that are accumulated as we go along, like piles of whatever

s3 items aren't saved transactionally; maybe we shouldn't be even imagining that it is possible to save such data transactionally

machines are different: don't treat data like machines

therefore, maybe we should just have different stores (or rather, repos)
so that savings of log rows is done directly by the phase, and isn't magically managed for them
by opaque and complicated movements of the dispatcher

each phase would try to save as many as possible until the rowStore batch was full



